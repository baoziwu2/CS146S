鉴于要求是英文，这里顺便翻译一下题意
### TODO 1

#### 目标
在 `app/services/extract.py` 中新增一个 LLM 驱动的 action item 抽取函数，使用 Ollama，并让输出是结构化 JSON（字符串数组）。
#### 实现
- 读取环境变量 `OLLAMA_MODEL` 作为模型名
- 空输入直接返回 []
- 使用 `Pydantic` 定义结构化输出 `schema(ActionItemsList)`
- 调用 `Ollama API`，使用 `format` 参数确保 JSON 输出
- 解析返回的 JSON 并提取行动项列表
#### 要点
- ollama 库内置了结构化库，具体的使用方法也贴了出来，直接喂给 bot 就好
- todo1 的写法比较重要（返回的一定要是json，不然后面的 task 会发现返回 200 但是无法解析）

### TODO 2
#### 目标
为 `extract_action_items_llm()` 编写单元测试，覆盖多种输入场景
#### 实现
1. 测试场景
	- 基本功能：正常文本提取
	- 空输入：空字符串或空白
	- 项目符号列表：包含 `-, *, 1.` 等
	- 关键词前缀：包含 todo:, action: 等
	- 混合格式：多种格式混合
2. Mock 策略
	- 使用 `monkeypatch` 模拟 `ollama.chat` 函数
	- 避免实际调用 LLM，提高测试速度和稳定性
#### 要点
怎么说呢，这个 Mock 测试策略其实是 bot 自己发现的

### TODO 3

#### 目标
让代码更工程化：API 契约清晰、路由更干净、初始化方式合理、错误更可控。
#### 实现
1. API 契约优化
	使用 `Pydantic` 模型定义请求/响应
	为每个端点添加清晰的文档字符串
	统一错误响应格式
2. 数据库层改进
	封装数据库连接管理
	使用上下文管理器确保连接正确关闭
	添加类型提示
3. 错误处理
	使用 `FastAPI` 的 `HTTPException` 统一错误响应
	为 LLM 调用添加异常处理和降级策略
#### 要点
感觉这个重构更换一个模型更合适？不过需要好好考虑新建模型的提示词需要提供什么信息

### TODO 4
#### 目标
1. 集成 LLM 提取为新端点，前端添加 "Extract LLM" 按钮
2. 添加获取所有笔记的端点，前端添加 "List Notes" 按钮
#### 要点
本身任务用 agent 是很容易完成的，直接复制要求就行

### TODO 5
#### 目标
写一份 README.md
#### 要点
现在 ai 对 readme 很清晰了，zero-shot 足够了，如果希望规范一下格式就规定一下小标题
